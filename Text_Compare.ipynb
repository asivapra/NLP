{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases: ['Sebastian Thrun', 'self-driving cars', 'Google', 'few people', 'the company', 'him', 'I', 'you', 'very senior CEOs', 'major American car companies', 'my hand', 'I', 'Thrun', 'an interview', 'Recode']\n",
      "Verbs: ['start', 'work', 'drive', 'take', 'tell', 'shake', 'turn', 'talk', 'say']\n",
      "Sebastian Thrun PERSON\n",
      "Google ORG\n",
      "2007 DATE\n",
      "American NORP\n",
      "Thrun ORG\n",
      "Recode PRODUCT\n",
      "earlier this week DATE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process whole documents\n",
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verb, gerund or present participle'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"VBG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sebastian Thrun, Google, 2007, American, Thrun, Recode, earlier this week)\n"
     ]
    }
   ],
   "source": [
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Install word vectots\n",
    "\n",
    "python -m spacy download en_core_web_lg\n",
    "\n",
    "python -m spacy download en_core_web_md\n",
    "\n",
    "python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
      "is be AUX VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. U.K. PROPN NNP compound X.X. False False\n",
      "startup startup NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog monkey 0.47752646\n",
      "dog tiger 0.43654656\n",
      "dog plantain 0.13001473\n",
      "cat monkey 0.5351813\n",
      "cat tiger 0.5413389\n",
      "cat plantain 0.15484892\n",
      "banana monkey 0.45207787\n",
      "banana tiger 0.2851668\n",
      "banana plantain 0.6150555\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "#nlp = spacy.load(\"en-core-web-md\")  # make sure to use larger model!\n",
    "tokens1 = nlp(\"dog cat banana\")\n",
    "tokens2 = nlp(\"monkey tiger plantain\")\n",
    "\n",
    "for token1 in tokens1:\n",
    "    for token2 in tokens2:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.8676397831908912\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "text1 = (\"\"\"\n",
    "Machine learning (ML) is the scientific study of algorithms and statistical models \n",
    "that computer systems use to perform a specific task without using explicit instructions, \n",
    "relying on patterns and inference instead. It is seen as a subset of artificial intelligence. \n",
    "Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", \n",
    "in order to make predictions or decisions without being explicitly programmed to perform the task.\n",
    "Machine learning algorithms are used in a wide variety of applications, such as email \n",
    "filtering and computer vision, where it is difficult or infeasible to develop a conventional \n",
    "algorithm for effectively performing the task.\n",
    "        \"\"\")\n",
    "doc1 = nlp(text1)\n",
    "\n",
    "text2 = (\"\"\"\n",
    "Machine learning is closely related to computational statistics, \n",
    "which focuses on making predictions using computers. \n",
    "The study of mathematical optimization delivers methods, \n",
    "theory and application domains to the field of machine learning. \n",
    "Data mining is a field of study within machine learning, and \n",
    "focuses on exploratory data analysis through unsupervised learning.\n",
    "In its application across business problems, machine learning is also referred to as predictive analytics.\n",
    "\"\"\")\n",
    "doc2 = nlp(text2)\n",
    "\n",
    "text3 = (\"\"\"\n",
    "The name machine learning was coined in 1959 by Arthur Samuel. \n",
    "Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms \n",
    "studied in the machine learning field: \"A computer program is said to learn from experience E \n",
    "with respect to some class of tasks T and performance measure P if its performance at tasks in T, \n",
    "as measured by P, improves with experience E.\" This definition of the tasks in which machine \n",
    "learning is concerned offers a fundamentally operational definition rather than defining the \n",
    "field in cognitive terms. This follows Alan Turing's proposal in his paper \"Computing Machinery and Intelligence\", \n",
    "in which the question \"Can machines think?\" is replaced with the question \n",
    "\"Can machines do what we (as thinking entities) can do?\". In Turing's proposal the various characteristics \n",
    "that could be possessed by a thinking machine and the various implications in constructing one are exposed.\n",
    "\"\"\")\n",
    "doc3 = nlp(text3)\n",
    "\n",
    "text4 = \"\"\"Titanic is a 1997 American epic romance and disaster film directed, written, co-produced, and co-edited by James Cameron. Incorporating both historical and fictionalized aspects, the film is based on accounts of the sinking of the RMS Titanic, and stars Leonardo DiCaprio and Kate Winslet as members of different social classes who fall in love aboard the ship during its ill-fated maiden voyage.\"\"\"\n",
    "doc4 = nlp(text4)\n",
    "\n",
    "text5 = \"\"\"Cameron's inspiration for the film came from his fascination with shipwrecks; he felt a love story interspersed with the human loss would be essential to convey the emotional impact of the disaster. Production began in 1995, when Cameron shot footage of the actual Titanic wreck. The modern scenes on the research vessel were shot on board the Akademik Mstislav Keldysh, which Cameron had used as a base when filming the wreck. Scale models, computer-generated imagery, and a reconstruction of the Titanic built at Baja Studios were used to re-create the sinking. The film was co-financed by Paramount Pictures and 20th Century Fox; the former handled distribution in North America while the latter released the film internationally. It was the most expensive film ever made at the time, with a production budget of $200 million.\"\"\"\n",
    "doc5 = nlp(text5)\n",
    "\n",
    "#print(doc1.text, \"\\n\", doc3.text, \"\\n\", doc1.similarity(doc3))\n",
    "print(\"Similarity:\", doc2.similarity(doc5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
